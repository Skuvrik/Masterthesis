{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for using DenseNet to tell if the MCA is visible for a slice\n",
    "Pipeline:\n",
    "- Import data\n",
    "- Find volume with the highest cumulative intensity for each patient\n",
    "- Discard all other volumes\n",
    "- Perform train, val, test split\n",
    "- Normalize data <- todo?\n",
    "- Initialize model\n",
    "- Train model\n",
    "- Test model\n",
    "- Visualize results\n",
    "- Use KMeans to extract AIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom as pdc\n",
    "from preprocess_utils import createImageIndexCSV, get_train_test_split_on_patients, get_max_intensity_for_dataset\n",
    "from dense_net import DenseNet3\n",
    "from model_utils import train_and_eval\n",
    "\n",
    "SEED = 41\n",
    "BATCH_SIZE = 8\n",
    "image_path = \"D:/iCAT_IMAGES\"\n",
    "aif_path = \"D:/AIFs/AIFs/durable/BorrSci_MR_Data/Output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import images (paths)\n",
    "image_data = createImageIndexCSV(image_path)\n",
    "# Import annotations\n",
    "mca_labels = pd.read_excel('MCA_labels.xlsx')\n",
    "mca_labels = mca_labels[:47] # Not all patients are annotated\n",
    "mca_labels = mca_labels.drop(mca_labels[mca_labels['Patient'] == 11].index) # Patient 11 is missing a file\n",
    "image_data = image_data[image_data['Patient'].isin(mca_labels['Patient'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the label dataframe to be compatible with efficient datahandling\n",
    "mca_labels = pd.melt(mca_labels, id_vars = ['Patient'], var_name='Slice', value_name='Label').sort_values(['Patient', 'Slice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here\n"
     ]
    }
   ],
   "source": [
    "vol_intensities = get_max_intensity_for_dataset(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
      "C:\\Users\\Sven Alrik\\AppData\\Local\\Temp\\ipykernel_16944\\1690949236.py:5: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead.\n",
      "  copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n"
     ]
    }
   ],
   "source": [
    "# Only keep the relevant volumes\n",
    "extra_vols = 3\n",
    "copy_data = image_data.copy()\n",
    "for patient, volume_index in zip(vol_intensities[:, 0], vol_intensities[:, 1]):\n",
    "    copy_data = copy_data.drop(copy_data[copy_data['Patient'] == int(patient)].index & copy_data[copy_data['Volume'] != int(volume_index)].index)\n",
    "    if extra_vols + volume_index < 48:\n",
    "        for i in range(int(volume_index)+1, extra_vols +int(volume_index) +1):\n",
    "            extra_data = image_data[image_data['Slice'].isin(mca_labels[(mca_labels['Patient'] == patient) & (mca_labels['Label'] == 1)]['Slice'])]\n",
    "            copy_data = pd.concat([copy_data, extra_data[extra_data['Volume'] == i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images = get_train_test_split_on_patients(copy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.isin(mca_labels['Patient'], np.unique(train_images['Patient']))\n",
    "train_labels = mca_labels[train_labels]\n",
    "test_labels = np.isin(mca_labels['Patient'], np.unique(test_images['Patient']))\n",
    "test_labels = mca_labels[test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size training data: 3139. Size test_data: 862\n",
      "Number of true labels in training: 66 of 864 (7.6%). True labels in test: 20 of 240 (8.3%)\n"
     ]
    }
   ],
   "source": [
    "label_train_true_size, label_train_size = len(train_labels[train_labels['Label'] == 1]), len(train_labels)\n",
    "label_test_true_size, label_test_size = len(test_labels[test_labels['Label'] == 1]), len(test_labels)\n",
    "print(f\"Size training data: {len(train_images)}. Size test_data: {len(test_images)}\")\n",
    "print(f\"Number of true labels in training: {label_train_true_size} of {label_train_size} ({round(label_train_true_size/label_train_size, 3)*100}%). True labels in test: {label_test_true_size} of {label_test_size} ({round(label_test_true_size/label_test_size, 3)*100}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_utils import SliceIntensityDataset\n",
    "train_dataset, test_dataset = SliceIntensityDataset(train_images, train_labels), SliceIntensityDataset(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters 365737\n"
     ]
    }
   ],
   "source": [
    "model = DenseNet3(64, num_classes=1, dropRate=0.2)\n",
    "print(f\"Total number of trainable parameters {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 2\n",
      "Losses: 8.031060218811035\n",
      "Epoch 2 of 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trained_model, losses \u001b[39m=\u001b[39m train_and_eval(model, test_loader, train_loader, \u001b[39m2\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Sven Alrik\\Documents\\dev\\Masterthesis\\model_utils.py:46\u001b[0m, in \u001b[0;36mtrain_and_eval\u001b[1;34m(model, test_loader, train_loader, epochs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m     45\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch \u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m     train(train_loader, model, criterion, optimizer)\n\u001b[0;32m     47\u001b[0m     losses \u001b[39m=\u001b[39m validate(test_loader, model, criterion)\n\u001b[0;32m     48\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLosses: \u001b[39m\u001b[39m{\u001b[39;00mlosses\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Sven Alrik\\Documents\\dev\\Masterthesis\\model_utils.py:9\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, criterion, optimizer)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i, (\u001b[39minput\u001b[39m,target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m      8\u001b[0m     target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39munsqueeze(target,\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     target \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39;49mcuda()\n\u001b[0;32m     10\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mpermute(torch\u001b[39m.\u001b[39munsqueeze(\u001b[39minput\u001b[39m, \u001b[39m0\u001b[39m), (\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[0;32m     11\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mcuda()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_model, losses = train_and_eval(model, test_loader, train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on training data:\n",
      "TP: 280, FP: 6, TN: 4395, FN: 23\n",
      "Accuracy: 0.99, Precision: 0.98, Recall: 0.92\n",
      "Performance on test data:\n",
      "TP: 10, FP: 5, TN: 215, FN: 10\n",
      "Accuracy: 0.94, Precision: 0.67, Recall: 0.5\n"
     ]
    }
   ],
   "source": [
    "def get_model_performance_metrics(model, images, labels):\n",
    "    # Copy dataframe due to the use of iterrows\n",
    "    images_copy = images.copy()\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    for _, selected in images_copy.iterrows():\n",
    "        model.eval()\n",
    "        image = pdc.read_file(selected['ImagePath'])\n",
    "        image = torch.tensor(np.expand_dims(image.pixel_array.astype(\"int32\"), axis=(0,1)), dtype=torch.float32)\n",
    "        image = image.to('cuda')\n",
    "        actual = labels[labels['Patient/slice'] == int(selected['Patient'])][int(selected['Slice'])].item()\n",
    "        predicted = int(round(torch.sigmoid(model(image)).item()))\n",
    "        if predicted == 1 and actual == 1:\n",
    "            TP += 1\n",
    "        elif predicted == 1 and actual == 0:\n",
    "            FP += 1\n",
    "        elif predicted == 0 and actual == 0:\n",
    "            TN += 1\n",
    "        elif predicted == 0 and actual == 1:\n",
    "            FN += 1\n",
    "        else:\n",
    "            pass\n",
    "    print(f\"TP: {TP}, FP: {FP}, TN: {TN}, FN: {FN}\")\n",
    "    print(f\"Accuracy: {round((TP+TN)/(TP+FP+TN+FN),2)}, Precision: {round(TP/(FP+TP), 2)}, Recall: {round(TP/(TP+FN), 2)}\")\n",
    "\n",
    "print(\"Performance on training data:\")\n",
    "get_model_performance_metrics(trained_model, train_images, train_labels)\n",
    "print(\"Performance on test data:\")\n",
    "get_model_performance_metrics(trained_model, test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.plot(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "254980037fba5f652ffae1d93b19c2d867700c56f5ec8345d05e9fe2c4071f2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
